# ğŸš€ End-to-End Data Engineering Pipeline

## ğŸ“Œ Overview
This project demonstrates a **complete end-to-end data engineering pipeline** that ingests raw data, performs cleaning and transformation, loads it into a relational data warehouse (SQLite), and runs analytical SQL queries to generate business insights.

The project follows **industry-style data engineering practices**, including clear folder structure, modular scripts, and separation of ingestion, transformation, storage, and analytics layers.

---

## ğŸ—ï¸ Architecture

Raw Data  
â¬‡  
**Ingestion (Python)**  
â¬‡  
**Transformation (Pandas)**  
â¬‡  
**Data Warehouse (SQLite)**  
â¬‡  
**Analytics (SQL Queries)**

---

## ğŸ“‚ Project Structure

data-engineering-pipeline/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Raw CSV data
â”‚ â””â”€â”€ clean/ # Cleaned CSV data after transformation
â”‚
â”œâ”€â”€ ingestion/
â”‚ â””â”€â”€ extract.py # Reads raw data
â”‚
â”œâ”€â”€ transformation/
â”‚ â””â”€â”€ transform.py # Cleans and prepares data
â”‚
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ schema.sql # Database schema (tables)
â”‚ â”œâ”€â”€ load.sql # SQL-based data loading (optional)
â”‚ â”œâ”€â”€ analytics.sql # Business analytics queries
â”‚ â””â”€â”€ warehouse/
â”‚ â””â”€â”€ load_to_sqlite.py # Python-based data loading into SQLite
â”‚
â”œâ”€â”€ warehouse.db # SQLite data warehouse
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ .gitignore

yaml
Copy code

---

## ğŸ§° Tech Stack

- **Python** â€“ Data ingestion & transformation
- **Pandas** â€“ Data cleaning and processing
- **SQLite** â€“ Lightweight data warehouse
- **SQL** â€“ Analytics and reporting
- **VS Code + SQLite Extension** â€“ Development & query execution
- **Git & GitHub** â€“ Version control

---

## ğŸ”„ Data Pipeline Workflow

### 1ï¸âƒ£ Data Ingestion
- Raw CSV files are read from the `data/raw/` directory.
- Implemented using Python scripts.

### 2ï¸âƒ£ Data Transformation
- Cleaning steps include:
  - Handling missing values
  - Standardizing column names
  - Ensuring correct data types
- Cleaned data is saved to `data/clean/`.

### 3ï¸âƒ£ Data Loading
- Cleaned CSV files are loaded into **SQLite** tables:
  - `customers`
  - `products`
  - `orders`
- Implemented using **Pandas + SQLite (`to_sql`)**.

### 4ï¸âƒ£ Data Analytics
- SQL queries are executed to generate insights such as:
  - Total revenue by product
  - Top customers by number of orders

---

## ğŸ“Š Sample Analytics Queries

### ğŸ”¹ Total Revenue by Product
```sql
SELECT
    p.product_name,
    SUM(o.quantity * p.price) AS total_revenue
FROM orders o
JOIN products p ON o.product_id = p.product_id
GROUP BY p.product_name
ORDER BY total_revenue DESC;
ğŸ”¹ Top Customers by Number of Orders
sql
Copy code
SELECT
    c.email AS customer,
    COUNT(o.order_id) AS total_orders
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.email
ORDER BY total_orders DESC;
â–¶ï¸ How to Run the Project
Step 1: Run Transformation
bash
Copy code
python transformation/transform.py
Step 2: Load Data into SQLite
bash
Copy code
python sql/warehouse/load_to_sqlite.py
Step 3: Run Analytics
Open analytics.sql

Right-click â†’ Run Query

View results in SQLite Explorer

ğŸ¯ Key Learnings
Building modular data pipelines

Handling real-world CSV data

Loading data into relational databases

Writing analytical SQL queries

Organizing projects like a data engineer

ğŸ“Œ Use Case
This project simulates a mini data warehouse for an e-commerce system and is suitable for:

Data Engineer portfolios

SQL & Python interview preparation

Demonstrating ETL/ELT concepts

ğŸ‘¤ Author
Pranav Viswambhar
B.Tech â€“ Computer Science Engineering
